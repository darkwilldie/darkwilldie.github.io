---
title: 机器学习
date: 2024-12-14 20:34:22
tags: machine learning
categories: machine learning
---

<!-- toc -->

## 监督学习

### 感知机

感知机是二分类的线性分类模型，输出为+1或-1。目的是找出一个超平面，将正负样本分开。用函数表示为

$$
f(x) = sign(w \cdot x + b)
$$

其中$w$是权重，$b$是偏置。$w$也是超平面的法向量，$b$是超平面的截距。

> 为什么$w$是超平面的法向量？
>
> 取任意两个点$x_1$和$x_2$，相减有$w \cdot (x_1 - x_2) = 0$，显然$(x_1 - x_2)\neq0$且$w\neq0$，所以$w$与$x_1 - x_2$垂直，即垂直于超平面。

#### 损失函数

$$
L(w, b) = -\sum_{x_i \in M} y_i (w \cdot x_i + b)
$$

$M$是误分类点的集合。误分类点满足$y_i (w \cdot x_i + b) \leq 0$。加上负号并求和，总损失 $\gt0$。

#### 梯度下降

损失$L(w, b)$对$w$和$b$的梯度为
$$
\nabla_w L(w, b) = -\sum_{x_i \in M} y_i x_i
$$

$$
\nabla_b L(w, b) = -\sum_{x_i \in M} y_i
$$

梯度下降法更新$w$和$b$：

$$
w \leftarrow w + \eta y_i x_i
$$

$$
b \leftarrow b + \eta y_i
$$

其中$\eta$是学习率。

#### 算法流程总结

1. 初始化$w$和$b$
2. 选取一个误分类点$(x_i, y_i)$
3. 更新$w$和$b$
4. 重复2和3，直到没有误分类点
