---
title: 记录两个代码错误
date: 2024-09-10 21:06:29
tags:
  - debug
  - normalization
---

# 错误 1

对两个二维张量计算外积时，等号左值没有用索引赋值，直接赋值的结果是后迭代的结果覆盖了前面的结果，最后 out 的值为最后一个计算出的值（而非所有的值）。由于 python 的广播机制，这个代码错误没有引起报错，但随着训练，梯度变得非常非常大（因为只盯着一个点计算损失），最后把输出炸成了 nan。

```python
    for j in range(X_std_batch.shape[0]):
        out = torch.outer(X_std_batch[j, :], Y_std_batch[j, :])
```

正确的代码应该为：

```python
    for j in range(X_std_batch.shape[0]):
        out[j, :] = torch.outer(X_std_batch[j, :], Y_std_batch[j, :])

```

理论上等价于：

```python
    out = torch.einsum('bi,bj->bij', X_std_batch, Y_std_batch)
```

明天学习一下内积和外积的性质和区别。

# 错误 2

在从迭代的矩阵计算升维成多个矩阵并行计算（二维函数升维成三维）时，需要把所有对应的维度都进行更新（比如维度 0 变为维度 1）。我就是没有更新全，导致在错误地维度进行了标准化和中心化，导致了损失函数波动很大，无法保持下降。

```python
    # 错误代码
    X = X - X.mean(dim=0)
    Y = Y - Y.mean(dim=0)
```

正确的代码应为：

```python
    # 标准化和中心化
    #! 二维计算改为三维，此处的dim应从0->1
    X = X - X.mean(dim=1).unsqueeze(1)
    Y = Y - Y.mean(dim=1).unsqueeze(1)
```
